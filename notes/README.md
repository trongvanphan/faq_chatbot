# ğŸš— FAQ Chatbot: Advanced Multi-Modal AI Assistant

An advanced chatbot system featuring **5 different AI approaches** for automotive FAQ, from simple Q&A to sophisticated RAG (Retrieval-Augmented Generation) with LangChain and ChromaDB.

## ğŸŒŸ Features

### **ğŸ¤– Tab 1: Automotive Bot (NEW!)**
- **LangChain ConversationalRetrievalChain** vá»›i memory
- **ChromaDB local vector database** cho fast similarity search
- **RAG (Retrieval-Augmented Generation)** pipeline
- **Conversational context** nhá»› toÃ n bá»™ cuá»™c trÃ² chuyá»‡n

### **ğŸ“š Tab 2: KB Management - RAG (NEW!)**
- **Document upload** (PDF, TXT, MD)
- **Automatic text chunking** vÃ  preprocessing
- **ChromaDB + FAISS** vector storage
- **Knowledge base statistics** vÃ  monitoring
- **Search functionality** trong vector database

### **ğŸ§  Tab 3: Context-Aware Bot**
- **Full conversation context management**
- **Reference understanding** ("nÃ³", "xe Ä‘Ã³")
- **Function calling** vá»›i context
- **Smart token management**

### **ğŸ”§ Tab 4: Function Calling Bot**
- **OpenAI Function Calling** capabilities
- **Retry mechanism** vá»›i exponential backoff
- Independent message processing

### **ğŸ“– Tab 5: Simple FAQ Bot**
- Basic FAQ responses
- Static knowledge base
- Simple Q&A matching

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Gradio UI     â”‚â”€â”€â”€â”€â”‚  LangChain Core  â”‚â”€â”€â”€â”€â”‚   ChromaDB      â”‚
â”‚   (5 Tabs)      â”‚    â”‚                  â”‚    â”‚  (Vector Store) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                        â”‚                        â”‚
         â–¼                        â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Context Manager â”‚    â”‚   OpenAI API     â”‚    â”‚   FAISS Index   â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Option 1: Automatic Setup (Recommended)
```bash
./setup.sh
```

### Option 2: Manual Setup
```bash
# 1. Create virtual environment
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# 2. Install dependencies
pip install -r requirements.txt

# 3. Configure environment
cp .env.example .env
# Edit .env and add your OpenAI API key

# 4. Run application
python app.py
```

## ğŸ“ Project Structure
## ğŸ“ Project Structure

```
faq_chatbot/
â”œâ”€â”€ app.py                      # ğŸ¯ Main Gradio application (5 tabs)
â”œâ”€â”€ automotive_bot.py           # ğŸ¤– NEW: LangChain + ChromaDB bot
â”œâ”€â”€ kb_manager.py              # ğŸ“š NEW: RAG knowledge base manager
â”œâ”€â”€ context_manager.py         # ğŸ§  Context-aware conversation manager
â”œâ”€â”€ faq_bot.py                 # ğŸ”§ Function calling & simple FAQ
â”œâ”€â”€ faq_data.py               # ğŸ“– Static FAQ dataset
â”œâ”€â”€ requirements.txt          # ğŸ“¦ Python dependencies
â”œâ”€â”€ .env.example             # âš™ï¸ Environment configuration template
â”œâ”€â”€ setup.sh                # ğŸš€ Automatic setup script
â”œâ”€â”€ chroma_db/              # ğŸ—„ï¸ ChromaDB vector database
â””â”€â”€ README.md               # ğŸ“‹ This file
```

## ğŸ”§ Configuration

### Environment Variables (.env)
```bash
# Required
OPENAI_API_KEY=your_openai_api_key_here

# Optional
RETRY_ATTEMPTS=3
RETRY_WAIT_MIN=1
RETRY_WAIT_MAX=10
CHROMA_DB_PATH=./chroma_db
```

## ğŸ’¡ Usage Guide

### 1. **ğŸ¤– Automotive Bot Tab**
- Ask any automotive questions
- Bot searches ChromaDB knowledge base
- Conversational memory maintains context
- Example: "What are hybrid engines?" â†’ "How do they compare to electric?"

### 2. **ğŸ“š KB Management Tab**
- Upload PDF/TXT documents about automotive topics
- System automatically processes and indexes
- Search existing knowledge base
- Monitor statistics and clear data if needed

### 3. **ğŸ§  Context-Aware Bot Tab**
- Multi-turn conversations with full context
- Understands references from previous messages
- Function calling with conversational context
- Example: "Suggest SUVs" â†’ "What about the Honda CR-V?" â†’ "What's its price?"

### 4. **ğŸ”§ Function Calling Bot Tab**
- OpenAI function calling without context
- Each message processed independently
- Good for specific queries

### 5. **ğŸ“– Simple FAQ Bot Tab**
- Basic static FAQ responses
- No AI processing, simple matching
- Fastest response time

## ğŸ› ï¸ Technical Details

### **LangChain Components**
- `ConversationalRetrievalChain`: Main conversation chain
- `OpenAIEmbeddings`: Text embedding for similarity search
- `ConversationBufferWindowMemory`: Conversation memory management
- `RecursiveCharacterTextSplitter`: Document chunking

### **ChromaDB Features**
- Persistent local vector database
- FAISS similarity search
- Automatic embedding storage
- Collection management

### **RAG Pipeline**
1. **Document Upload** â†’ Text extraction (PDF/TXT)
2. **Text Splitting** â†’ Chunking with overlap
3. **Embedding** â†’ OpenAI embeddings
4. **Storage** â†’ ChromaDB vector store
5. **Retrieval** â†’ Similarity search
6. **Generation** â†’ LLM response with context

## ğŸš€ Development

### Adding New Features
```python
# Add new bot type
from your_new_bot import YourNewBot

def your_bot_interface(user_input, history):
    # Your implementation
    pass

# Add to app.py tabs
with gr.Tab("ğŸ†• Your New Bot"):
    # Your UI components
    pass
```

### Extending Knowledge Base
```python
# Add new document types in kb_manager.py
def process_new_format(self, file_path: str):
    # Your processing logic
    pass
```

## ğŸ“Š Monitoring

- **ChromaDB stats**: Number of documents, chunks, collection status
- **Conversation tracking**: Message count, topics, context size
- **Error handling**: Comprehensive error messages and fallbacks
- **Performance**: Retry mechanisms with exponential backoff

## ğŸ” Troubleshooting

### Common Issues
1. **OpenAI API Key**: Make sure it's set in `.env`
2. **Dependencies**: Run `pip install -r requirements.txt`
3. **ChromaDB**: Delete `chroma_db/` folder to reset
4. **Memory**: Restart app if conversations get too long

### Debug Mode
```bash
# Run with verbose logging
LANGCHAIN_VERBOSE=true python app.py
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch: `git checkout -b feature/new-feature`
3. Commit changes: `git commit -am 'Add new feature'`
4. Push to branch: `git push origin feature/new-feature`
5. Submit pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **OpenAI** for GPT models and embeddings
- **LangChain** for RAG framework
- **ChromaDB** for vector database
- **Gradio** for web interface
- **FAISS** for similarity search
   - Clone this repository to your local machine.
2. **Install dependencies**
   - Run `pip install -r requirements.txt` to install required packages.
3. **Review and update FAQ data**
   - Open `faq_data.py` to view or edit the list of FAQs and answers.
4. **Understand the chatbot logic**
   - Check `faq_bot.py` to see how user questions are matched to FAQ answers.
5. **Run the application**
   - Start the chatbot by running `python app.py`.
   - Open the provided local URL in your browser to interact with the chatbot.
6. **Customize as needed**
   - Add new questions/answers in `faq_data.py`.
   - Adjust logic in `faq_bot.py` for improved matching or features.

### Installation
1. Clone this repository:
   ```bash
   git clone <repo-url>
   cd faq_chatbot
   ```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

### Running the Chatbot
Start the Gradio app:
```bash
python app.py
```
This will launch a local web server. Open the provided URL in your browser to interact with the chatbot.

## Customization
- Add or modify FAQs in `faq_data.py` to update the chatbot's knowledge base.

## Requirements
- Python 3.7+
- gradio

## License
This project is for educational purposes.
