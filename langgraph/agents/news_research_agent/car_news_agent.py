from services import get_azure_llm, get_tavily_search
from langchain_core.messages import SystemMessage, HumanMessage
llm = get_azure_llm()

def evaluate(prompt):
    response = llm.invoke([
        SystemMessage(content="""B·∫°n l√† tr·ª£ l√Ω chuy√™n gia v·ªÅ √¥ t√¥.

        C√¥ng vi·ªác c·ªßa b·∫°n l√† ƒë√°nh gi√° xem m·ªôt b√†i b√°o c√≥ li√™n quan tr·ª±c ti·∫øp ƒë·∫øn c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng v·ªÅ xe h∆°i, √¥ t√¥, xu h∆∞·ªõng √¥ t√¥, m·∫´u xe, an to√†n, gi√° c·∫£, t√≠nh nƒÉng, ho·∫∑c c·∫≠p nh·∫≠t ng√†nh hay kh√¥ng.

        Xem x√©t ti√™u ƒë·ªÅ tin t·ª©c, n·ªôi dung v√† c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng.

        N·∫øu tin t·ª©c tr·∫£ l·ªùi r√µ r√†ng ho·∫∑c cung c·∫•p th√¥ng tin c√≥ gi√° tr·ªã li√™n quan ƒë·∫øn c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng, h√£y tr·∫£ l·ªùi:
        YES

        N·∫øu tin t·ª©c kh√¥ng li√™n quan tr·ª±c ti·∫øp ho·∫∑c ch·ªâ ƒë·ªÅ c·∫≠p m∆° h·ªì ƒë·∫øn c√°c ch·ªß ƒë·ªÅ li√™n quan, h√£y tr·∫£ l·ªùi:
        NO

        Ch·ªâ tr·∫£ l·ªùi YES ho·∫∑c NO."""),
        HumanMessage(content=prompt)
    ])
    
    return response.content

def external_news_agent(state):
    question = state.get("question", "").strip()
    if not question:
        return {**state, "external_context": "‚ö†Ô∏è No question provided for news search."}

    try:
        focused_query = f"Latest automotive news about: {question}"
        response = get_tavily_search().invoke(focused_query)
        articles = []
        for res in response.get("results", []):
            title = res.get("title", "").strip()
            url = res.get("url", "").strip()
            content = res.get("content", "").strip()

            # Keep articles with either content or meaningful title + url
            if title and url:
                articles.append({
                    "title": title,
                    "url": url,
                    "content": content or "No detailed content available."
                })

        if not articles:
            return {**state, "external_context": "‚ö†Ô∏è No usable news articles found."}

        relevant_articles = []
        print(f"üîç Found {articles} articles, checking relevance...")
        for article in articles:
            check_prompt = f"""
You are a helpful assistant checking news relevance.

User question:
"{question}"

News title:
"{article['title']}"

News content:
"{article['content']}"

Is this news relevant to the user's question? Reply with YES or NO.
"""
            try:
                llm_response = evaluate(check_prompt).upper()
                print(f"üîç LLM Relevance Check: {llm_response} for article '{article['title']}'")
                if llm_response == "YES":
                    relevant_articles.append(article)
            except Exception as e:
                print(f"‚ö†Ô∏è LLM relevance check failed for article '{article['title']}': {str(e)}")
                continue  # Continue with next article

        if not relevant_articles:
            return {**state, "answer": "‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y tin t·ª©c li√™n quan ƒë·∫øn c√¢u h·ªèi c·ªßa b·∫°n v·ªÅ √¥ t√¥."}

        # Format in Vietnamese
        combined_news = "üì∞ **Tin t·ª©c √¥ t√¥ m·ªõi nh·∫•t:**\n\n"
        combined_news += "\n\n".join(
            f"### ÔøΩ {art['title']}\n"
            f"{art['content'][:300]}...\n"
            f"[üîó ƒê·ªçc th√™m]({art['url']})"
            for art in relevant_articles
        )

        return {**state, "answer": combined_news}

    except Exception as e:
        return {**state, "answer": f"‚ö†Ô∏è Kh√¥ng th·ªÉ t√¨m ki·∫øm tin t·ª©c: {str(e)}"}
