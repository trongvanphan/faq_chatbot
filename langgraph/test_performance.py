"""
Performance Test Script
So sÃ¡nh tá»‘c Ä‘á»™ giá»¯a agent gá»‘c vÃ  agent Ä‘Æ°á»£c tá»‘i Æ°u
"""

import time
from chat_state import ChatState
from agents.recommendation.recommendation_agent import car_recommendation_agent
from agents.recommendation.recommendation_agent_optimized import optimized_car_agent

# Test cases tiáº¿ng Viá»‡t
test_cases = [
    "TÃ´i muá»‘n mua xe vá»›i ngÃ¢n sÃ¡ch 800 triá»‡u cho gia Ä‘Ã¬nh 4 ngÆ°á»i",
    "Xe nÃ o tá»‘t nháº¥t dÆ°á»›i 1 tá»· Ä‘á»“ng Ä‘á»ƒ Ä‘i lÃ m hÃ ng ngÃ y?",
    "Gá»£i Ã½ xe luxury trong táº§m 2 tá»· cho doanh nhÃ¢n",
    "Xe hybrid nÃ o Ä‘Ã¡ng mua nháº¥t á»Ÿ Viá»‡t Nam?",
    "TÃ´i cáº§n xe 7 chá»— cho gia Ä‘Ã¬nh Ä‘Ã´ng ngÆ°á»i"
]

def test_agent_performance(agent, agent_name, test_question):
    """Test performance cá»§a má»™t agent"""
    print(f"\nğŸš€ Testing {agent_name}...")
    print(f"Question: {test_question}")
    
    start_time = time.time()
    
    try:
        # Táº¡o state
        state = ChatState(question=test_question, answer="")
        
        # Process request
        if hasattr(agent, 'process_recommendation_request'):
            result = agent.process_recommendation_request(state)
        else:
            result = agent.process_recommendation_fast(state)
        
        end_time = time.time()
        elapsed = end_time - start_time
        
        print(f"â±ï¸  Time taken: {elapsed:.2f} seconds")
        print(f"ğŸ“ Response length: {len(result['answer'])} characters")
        print(f"âœ… Success: {bool(result['answer'])}")
        
        return elapsed, len(result['answer'])
        
    except Exception as e:
        end_time = time.time()
        elapsed = end_time - start_time
        print(f"âŒ Error: {str(e)}")
        print(f"â±ï¸  Time before error: {elapsed:.2f} seconds")
        return elapsed, 0

def run_performance_comparison():
    """Cháº¡y so sÃ¡nh hiá»‡u suáº¥t"""
    print("ğŸ”¥ CAR RECOMMENDATION AGENT PERFORMANCE TEST")
    print("=" * 60)
    
    original_times = []
    optimized_times = []
    
    for i, question in enumerate(test_cases, 1):
        print(f"\nğŸ“‹ TEST CASE {i}/{len(test_cases)}")
        print("-" * 40)
        
        # Test original agent
        orig_time, orig_length = test_agent_performance(
            car_recommendation_agent, 
            "Original Agent", 
            question
        )
        
        # Test optimized agent  
        opt_time, opt_length = test_agent_performance(
            optimized_car_agent,
            "Optimized Agent",
            question
        )
        
        # Calculate improvement
        if orig_time > 0:
            improvement = ((orig_time - opt_time) / orig_time) * 100
            print(f"ğŸš€ Speed improvement: {improvement:.1f}% faster")
        
        original_times.append(orig_time)
        optimized_times.append(opt_time)
        
        print("-" * 40)
    
    # Overall statistics
    print(f"\nğŸ“Š OVERALL RESULTS")
    print("=" * 60)
    
    avg_original = sum(original_times) / len(original_times)
    avg_optimized = sum(optimized_times) / len(optimized_times)
    overall_improvement = ((avg_original - avg_optimized) / avg_original) * 100
    
    print(f"â±ï¸  Average Original Time: {avg_original:.2f} seconds")
    print(f"â±ï¸  Average Optimized Time: {avg_optimized:.2f} seconds")
    print(f"ğŸš€ Overall Speed Improvement: {overall_improvement:.1f}% faster")
    
    # Recommendations
    print(f"\nğŸ’¡ RECOMMENDATIONS")
    print("-" * 30)
    if avg_optimized < 3:
        print("âœ… Optimized agent meets performance target (<3s)")
    else:
        print("âš ï¸  Still slower than target. Consider further optimizations:")
        print("   â€¢ Reduce ChromaDB query size")
        print("   â€¢ Implement more aggressive caching")
        print("   â€¢ Pre-process common queries")
    
    return {
        "avg_original": avg_original,
        "avg_optimized": avg_optimized,
        "improvement_percent": overall_improvement,
        "individual_times": {
            "original": original_times,
            "optimized": optimized_times
        }
    }

if __name__ == "__main__":
    results = run_performance_comparison()
    
    # Save results to file for analysis
    import json
    with open("performance_test_results.json", "w", encoding="utf-8") as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ Results saved to performance_test_results.json")
