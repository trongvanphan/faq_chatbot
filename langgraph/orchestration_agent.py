"""
Master Orchestration Agent
Coordinates between different specialized agents and handles routing decisions.
"""

from typing import Dict, Any, List
from chat_state import ChatState
from agents.news_research_agent.car_news_agent import external_news_agent
from services import get_azure_llm
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableSequence
from langchain_core.output_parsers import StrOutputParser
from agents.recommendation.recommendation_agent_optimized import recommend_car_fast
from langgraph.graph import StateGraph, END
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class MasterOrchestrationAgent:
    """
    Master agent that orchestrates between different specialized agents.
    Handles intent classification and routing to appropriate agents.
    """
    
    def __init__(self):
        self.llm = get_azure_llm()
        self.available_agents = {
            "recommendation": {
                "function": recommend_car_fast,
                "description": "Car recommendation and buying advice",
                "keywords": ["car", "recommend", "buy", "purchase", "vehicle", "budget", "family car", "commute"]
            },
            "retrieve_docs": {
                "function": self.retrieve_docs,
                "description": "Document retrieval and knowledge base search",
                "keywords": ["document", "search", "find", "information", "knowledge"]
            },
            "search_news": {
                "function": self.search_news,
                "description": "News search and current events",
                "keywords": ["news", "latest", "update", "current", "recent", "breaking"]
            }
        }
        self.setup_intent_classifier()
        self.setup_workflow()
    
    def setup_intent_classifier(self):
        """Set up the intent classification system."""
        agent_descriptions = "\n".join([
            f"- {name}: {info['description']}"
            for name, info in self.available_agents.items()
        ])
        
        self.intent_prompt = PromptTemplate.from_template(
            f"""B·∫°n l√† m·ªôt tr·ª£ l√Ω AI chuy√™n v·ªÅ √¥ t√¥ v√† xe h∆°i t·∫°i Vi·ªát Nam. B·∫°n ch·ªâ ƒë∆∞·ª£c tr·∫£ l·ªùi c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn:
            - T∆∞ v·∫•n mua xe, g·ª£i √Ω xe ph√π h·ª£p
            - Th√¥ng tin k·ªπ thu·∫≠t v·ªÅ xe √¥ t√¥
            - Tin t·ª©c v·ªÅ ng√†nh √¥ t√¥
            - B·∫£o d∆∞·ª°ng v√† s·ª≠a ch·ªØa xe
            - So s√°nh c√°c d√≤ng xe
            
            QUAN TR·ªåNG: N·∫øu c√¢u h·ªèi KH√îNG li√™n quan ƒë·∫øn √¥ t√¥, xe h∆°i, ho·∫∑c giao th√¥ng, h√£y tr·∫£ l·ªùi "INVALID_QUESTION".
            
            C√°c agent c√≥ s·∫µn:
            {agent_descriptions}
            
            Ph√¢n lo·∫°i c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng th√†nh m·ªôt trong c√°c lo·∫°i:
            - recommendation (t∆∞ v·∫•n mua xe, g·ª£i √Ω xe, so s√°nh xe)
            - retrieve_docs (t√¨m ki·∫øm th√¥ng tin, t√†i li·ªáu v·ªÅ xe)
            - search_news (tin t·ª©c v·ªÅ √¥ t√¥, xu h∆∞·ªõng m·ªõi)
            - INVALID_QUESTION (c√¢u h·ªèi kh√¥ng li√™n quan ƒë·∫øn √¥ t√¥)
            
            C√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng: {{question}}
            
            Ch·ªâ tr·∫£ l·ªùi t√™n agent (recommendation/retrieve_docs/search_news/INVALID_QUESTION)."""
        )
        
        self.intent_classifier: RunnableSequence = (
            self.intent_prompt 
            | self.llm 
            | StrOutputParser()
        )
    
    def classify_intent(self, question: str) -> str:
        """
        Classify user intent and determine which agent to route to.
        """
        try:
            intent = self.intent_classifier.invoke({"question": question}).strip().lower()
            
            # Handle invalid questions (guardrail)
            if intent == "invalid_question":
                logger.info(f"Blocked invalid question: {question[:50]}...")
                return "invalid_question"
            
            # Validate intent
            if intent not in self.available_agents:
                logger.warning(f"Unknown intent '{intent}', defaulting to retrieve_docs")
                intent = "retrieve_docs"
            
            logger.info(f"Classified intent: {intent} for question: {question[:50]}...")
            return intent
            
        except Exception as e:
            logger.error(f"Error in intent classification: {e}")
            return "retrieve_docs"  # Default fallback
    
    def route_user_input(self, state: ChatState) -> ChatState:
        """
        Route user input to appropriate agent based on intent classification.
        """
        question = state["question"]
        intent = self.classify_intent(question)
        
        # Handle invalid questions with Vietnamese response
        if intent == "invalid_question":
            return {
                **state, 
                "answer": "üö´ Xin l·ªói, t√¥i ch·ªâ c√≥ th·ªÉ tr·∫£ l·ªùi c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn √¥ t√¥, xe h∆°i v√† giao th√¥ng. \n\n"
                         "üìã T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:\n"
                         "‚Ä¢ üöó T∆∞ v·∫•n mua xe ph√π h·ª£p\n"
                         "‚Ä¢ üîß Th√¥ng tin k·ªπ thu·∫≠t v·ªÅ xe\n" 
                         "‚Ä¢ üì∞ Tin t·ª©c ng√†nh √¥ t√¥\n"
                         "‚Ä¢ üõ†Ô∏è B·∫£o d∆∞·ª°ng v√† s·ª≠a ch·ªØa xe\n"
                         "‚Ä¢ ‚öñÔ∏è So s√°nh c√°c d√≤ng xe\n\n"
                         "Vui l√≤ng ƒë·∫∑t c√¢u h·ªèi v·ªÅ √¥ t√¥ ƒë·ªÉ t√¥i c√≥ th·ªÉ h·ªó tr·ª£ b·∫°n t·ªët nh·∫•t! üòä",
                "next_step": "generate_answer"
            }
        
        logger.info(f"Routing to agent: {intent}")
        return {**state, "next_step": intent}
    
    def retrieve_docs(self, state: ChatState) -> ChatState:
        """
        Handle document retrieval requests using enhanced knowledge base.
        """
        try:
            from knowledge_base import knowledge_base
            
            # Use the enhanced knowledge base search
            results = knowledge_base.search_similar(state["question"], k=4)
            
            if results:
                # Convert search results to document format for compatibility
                docs = []
                for result in results:
                    # Create a mock document object
                    class MockDoc:
                        def __init__(self, content, metadata):
                            self.page_content = content
                            self.metadata = metadata
                    
                    docs.append(MockDoc(result["content"], result["metadata"]))
                
                return {**state, "context_docs": docs}
            else:
                return {**state, "context_docs": [], "answer": "I couldn't find relevant information in the knowledge base."}
                
        except Exception as e:
            logger.error(f"Error in enhanced document retrieval: {e}")
            # Fallback to basic retrieval if enhanced version fails
            try:
                from services import get_vectordb
                retriever = get_vectordb().as_retriever(search_kwargs={"k": 4}) 
                docs = retriever.get_relevant_documents(state["question"])
                return {**state, "context_docs": docs}
            except Exception as e2:
                logger.error(f"Fallback document retrieval also failed: {e2}")
                return {**state, "context_docs": [], "answer": "I'm having trouble accessing the document database right now."}
    
    def search_news(self, state: ChatState) -> ChatState:
        return external_news_agent(state)
    
    def generate_answer(self, state: ChatState) -> ChatState:
        """
        Generate final answer, handling both document-based and direct agent responses.
        """
        question = state["question"]
        chat_history = state["chat_history"]
        docs = state.get("context_docs", [])
        
        # If context_docs are available, use them for answer generation
        if docs:
            try:
                context = "\n".join([doc.page_content for doc in docs])
                enhanced_prompt = f"""
                D·ª±a tr√™n c√°c t√†i li·ªáu sau, h√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng b·∫±ng ti·∫øng Vi·ªát m·ªôt c√°ch chi ti·∫øt v√† h·ªØu √≠ch.
                
                T√†i li·ªáu tham kh·∫£o: {context}
                
                C√¢u h·ªèi: {question}
                
                Vui l√≤ng tr·∫£ l·ªùi b·∫±ng ti·∫øng Vi·ªát v·ªõi th√¥ng tin ch√≠nh x√°c t·ª´ t√†i li·ªáu.
                N·∫øu t√†i li·ªáu kh√¥ng ch·ª©a th√¥ng tin li√™n quan, h√£y n√≥i r√µ r√†ng.
                """
                response = self.llm.invoke(enhanced_prompt)
                return {**state, "answer": response.content}
            except Exception as e:
                logger.error(f"Error in answer generation: {e}")
                return {**state, "answer": "T√¥i g·∫∑p l·ªói khi x·ª≠ l√Ω t√†i li·ªáu. Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c ƒë·∫∑t c√¢u h·ªèi kh√°c."}
        
        # If answer is already set by an agent (recommendation/news), return it
        elif "answer" in state and state["answer"]:
            return state
        
        # Fallback response
        else:
            return {**state, "answer": "T√¥i kh√¥ng ch·∫Øc ch·∫Øn v·ªÅ c√¢u h·ªèi n√†y. B·∫°n c√≥ th·ªÉ h·ªèi l·∫°i b·∫±ng c√°ch kh√°c ƒë∆∞·ª£c kh√¥ng? ü§î"}
    
    def setup_workflow(self):
        """
        Set up the LangGraph workflow for the orchestration agent.
        """
        self.graph = StateGraph(ChatState)
        
        # Add all nodes
        self.graph.add_node("router", self.route_user_input)
        self.graph.add_node("retrieve_docs", self.retrieve_docs)
        self.graph.add_node("recommendation", recommend_car_fast)
        self.graph.add_node("search_news", self.search_news)
        self.graph.add_node("generate_answer", self.generate_answer)
        
        # Set entry point
        self.graph.set_entry_point("router")
        
        # Add conditional routing from router
        self.graph.add_conditional_edges("router", lambda state: state["next_step"], {
            "retrieve_docs": "retrieve_docs",
            "recommendation": "recommendation", 
            "search_news": "search_news",
            "generate_answer": "generate_answer"  # For invalid questions
        })
        
        # Connect all paths to answer generation
        self.graph.add_edge("retrieve_docs", "generate_answer")
        self.graph.add_edge("recommendation", "generate_answer") 
        self.graph.add_edge("search_news", "generate_answer")
        self.graph.add_edge("generate_answer", END)
        
        # Compile the workflow
        self.workflow = self.graph.compile()
        logger.info("Master orchestration workflow compiled successfully")
    
    def process_query(self, question: str, chat_history: List = None) -> Dict[str, Any]:
        """
        Process a user query through the orchestration system.
        """
        if chat_history is None:
            chat_history = []
        
        try:
            result = self.workflow.invoke({
                "question": question,
                "chat_history": chat_history,
                "context_docs": [],
                "answer": "",
                "next_step": ""
            })
            return result
        except Exception as e:
            logger.error(f"Error processing query: {e}")
            return {
                "question": question,
                "answer": "I encountered an error while processing your request. Please try again.",
                "chat_history": chat_history
            }
    
    def add_agent(self, name: str, function, description: str, keywords: List[str]):
        """
        Add a new specialized agent to the orchestration system.
        """
        self.available_agents[name] = {
            "function": function,
            "description": description,
            "keywords": keywords
        }
        
        # Rebuild intent classifier with new agent
        self.setup_intent_classifier()
        logger.info(f"Added new agent: {name}")
    
    def get_available_agents(self) -> Dict[str, Dict[str, Any]]:
        """
        Get information about all available agents.
        """
        return self.available_agents.copy()

    def get_workflow_image(self) -> bytes:
        """
        Returns a PNG image (as bytes) of the LangGraph workflow.
        """
        try:
            return self.workflow.get_graph().draw_mermaid_png()
        except Exception as e:
            logger.error(f"Error generating workflow image: {e}")
            return None
# Create global master orchestration agent instance
master_agent = MasterOrchestrationAgent()
