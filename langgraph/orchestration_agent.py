"""
Master Orchestration Agent
Coordinates between different specialized agents and handles routing decisions.
"""

from typing import Dict, Any, List
from chat_state import ChatState
from agents.news_research_agent.car_news_agent import external_news_agent
from services import get_azure_llm
from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableSequence
from langchain_core.output_parsers import StrOutputParser
from agents.recommendation.recommendation_agent_optimized import recommend_car_fast
from langgraph.graph import StateGraph, END
import logging

# Set up logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class MasterOrchestrationAgent:
    """
    Master agent that orchestrates between different specialized agents.
    Handles intent classification and routing to appropriate agents.
    """
    
    def __init__(self):
        self.llm = get_azure_llm()
        self.available_agents = {
            "recommendation": {
                "function": recommend_car_fast,
                "description": "Car recommendation and buying advice",
                "keywords": ["car", "recommend", "buy", "purchase", "vehicle", "budget", "family car", "commute"]
            },
            "retrieve_docs": {
                "function": self.retrieve_docs,
                "description": "Document retrieval and knowledge base search",
                "keywords": ["document", "search", "find", "information", "knowledge"]
            },
            "search_news": {
                "function": self.search_news,
                "description": "News search and current events",
                "keywords": ["news", "latest", "update", "current", "recent", "breaking"]
            }
        }
        self.setup_intent_classifier()
        self.setup_workflow()
    
    def setup_intent_classifier(self):
        """Set up the intent classification system."""
        agent_descriptions = "\n".join([
            f"- {name}: {info['description']}"
            for name, info in self.available_agents.items()
        ])
        
        self.intent_prompt = PromptTemplate.from_template(
            f"""Báº¡n lÃ  má»™t trá»£ lÃ½ AI chuyÃªn vá» Ã´ tÃ´ vÃ  xe hÆ¡i táº¡i Viá»‡t Nam. Báº¡n chá»‰ Ä‘Æ°á»£c tráº£ lá»i cÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n:
            - TÆ° váº¥n mua xe, gá»£i Ã½ xe phÃ¹ há»£p
            - ThÃ´ng tin ká»¹ thuáº­t vá» xe Ã´ tÃ´
            - Tin tá»©c vá» ngÃ nh Ã´ tÃ´
            - Báº£o dÆ°á»¡ng vÃ  sá»­a chá»¯a xe
            - So sÃ¡nh cÃ¡c dÃ²ng xe
            
            QUAN TRá»ŒNG: Náº¿u cÃ¢u há»i KHÃ”NG liÃªn quan Ä‘áº¿n Ã´ tÃ´, xe hÆ¡i, hoáº·c giao thÃ´ng, hÃ£y tráº£ lá»i "INVALID_QUESTION".
            
            CÃ¡c agent cÃ³ sáºµn:
            {agent_descriptions}
            
            PhÃ¢n loáº¡i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng thÃ nh má»™t trong cÃ¡c loáº¡i:
            - recommendation (tÆ° váº¥n mua xe, gá»£i Ã½ xe, so sÃ¡nh xe)
            - retrieve_docs (tÃ¬m kiáº¿m thÃ´ng tin, tÃ i liá»‡u vá» xe)
            - search_news (tin tá»©c vá» Ã´ tÃ´, xu hÆ°á»›ng má»›i)
            - INVALID_QUESTION (cÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n Ã´ tÃ´)
            
            CÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng: {{question}}
            
            Chá»‰ tráº£ lá»i tÃªn agent (recommendation/retrieve_docs/search_news/INVALID_QUESTION)."""
        )
        
        self.intent_classifier: RunnableSequence = (
            self.intent_prompt 
            | self.llm 
            | StrOutputParser()
        )
    
    def classify_intent(self, question: str) -> str:
        """
        Classify user intent and determine which agent to route to.
        """
        try:
            intent = self.intent_classifier.invoke({"question": question}).strip().lower()
            
            # Handle invalid questions (guardrail)
            if intent == "invalid_question":
                logger.info(f"Blocked invalid question: {question[:50]}...")
                return "invalid_question"
            
            # Validate intent
            if intent not in self.available_agents:
                logger.warning(f"Unknown intent '{intent}', defaulting to retrieve_docs")
                intent = "retrieve_docs"
            
            logger.info(f"Classified intent: {intent} for question: {question[:50]}...")
            return intent
            
        except Exception as e:
            logger.error(f"Error in intent classification: {e}")
            return "retrieve_docs"  # Default fallback
    
    def route_user_input(self, state: ChatState) -> ChatState:
        """
        Route user input to appropriate agent based on intent classification.
        """
        question = state["question"]
        intent = self.classify_intent(question)
        
        # Handle invalid questions with Vietnamese response
        if intent == "invalid_question":
            return {
                **state, 
                "answer": "ðŸš« Xin lá»—i, tÃ´i chá»‰ cÃ³ thá»ƒ tráº£ lá»i cÃ¡c cÃ¢u há»i liÃªn quan Ä‘áº¿n Ã´ tÃ´, xe hÆ¡i vÃ  giao thÃ´ng. \n\n"
                         "ðŸ“‹ TÃ´i cÃ³ thá»ƒ giÃºp báº¡n:\n"
                         "â€¢ ðŸš— TÆ° váº¥n mua xe phÃ¹ há»£p\n"
                         "â€¢ ðŸ”§ ThÃ´ng tin ká»¹ thuáº­t vá» xe\n" 
                         "â€¢ ðŸ“° Tin tá»©c ngÃ nh Ã´ tÃ´\n"
                         "â€¢ ðŸ› ï¸ Báº£o dÆ°á»¡ng vÃ  sá»­a chá»¯a xe\n"
                         "â€¢ âš–ï¸ So sÃ¡nh cÃ¡c dÃ²ng xe\n\n"
                         "Vui lÃ²ng Ä‘áº·t cÃ¢u há»i vá» Ã´ tÃ´ Ä‘á»ƒ tÃ´i cÃ³ thá»ƒ há»— trá»£ báº¡n tá»‘t nháº¥t! ðŸ˜Š",
                "next_step": "generate_answer"
            }
        
        logger.info(f"Routing to agent: {intent}")
        return {**state, "next_step": intent}
    
    def retrieve_docs(self, state: ChatState) -> ChatState:
        """
        Handle document retrieval requests using enhanced knowledge base.
        """
        try:
            from knowledge_base import knowledge_base
            
            # Use the enhanced knowledge base search
            results = knowledge_base.search_similar(state["question"], k=4)
            
            if results:
                # Convert search results to document format for compatibility
                docs = []
                for result in results:
                    # Create a mock document object
                    class MockDoc:
                        def __init__(self, content, metadata):
                            self.page_content = content
                            self.metadata = metadata
                    
                    docs.append(MockDoc(result["content"], result["metadata"]))
                
                return {**state, "context_docs": docs}
            else:
                return {**state, "context_docs": [], "answer": "I couldn't find relevant information in the knowledge base."}
                
        except Exception as e:
            logger.error(f"Error in enhanced document retrieval: {e}")
            # Fallback to basic retrieval if enhanced version fails
            try:
                from services import get_vectordb
                retriever = get_vectordb().as_retriever(search_kwargs={"k": 4}) 
                docs = retriever.get_relevant_documents(state["question"])
                return {**state, "context_docs": docs}
            except Exception as e2:
                logger.error(f"Fallback document retrieval also failed: {e2}")
                return {**state, "context_docs": [], "answer": "I'm having trouble accessing the document database right now."}
    
    def search_news(self, state: ChatState) -> ChatState:
        return external_news_agent(state)
    
    def generate_answer(self, state: ChatState) -> ChatState:
        """
        Generate final answer, handling both document-based and direct agent responses.
        """
        question = state["question"]
        chat_history = state["chat_history"]
        docs = state.get("context_docs", [])
        
        # If context_docs are available, use them for answer generation
        if docs:
            try:
                context = "\n".join([doc.page_content for doc in docs])
                enhanced_prompt = f"""
                Dá»±a trÃªn cÃ¡c tÃ i liá»‡u sau, hÃ£y tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng báº±ng tiáº¿ng Viá»‡t má»™t cÃ¡ch chi tiáº¿t vÃ  há»¯u Ã­ch.
                
                TÃ i liá»‡u tham kháº£o: {context}
                
                CÃ¢u há»i: {question}
                
                Vui lÃ²ng tráº£ lá»i báº±ng tiáº¿ng Viá»‡t vá»›i thÃ´ng tin chÃ­nh xÃ¡c tá»« tÃ i liá»‡u.
                Náº¿u tÃ i liá»‡u khÃ´ng chá»©a thÃ´ng tin liÃªn quan, hÃ£y nÃ³i rÃµ rÃ ng.
                """
                response = self.llm.invoke(enhanced_prompt)
                return {**state, "answer": response.content}
            except Exception as e:
                logger.error(f"Error in answer generation: {e}")
                return {**state, "answer": "TÃ´i gáº·p lá»—i khi xá»­ lÃ½ tÃ i liá»‡u. Vui lÃ²ng thá»­ láº¡i hoáº·c Ä‘áº·t cÃ¢u há»i khÃ¡c."}
        
        # If answer is already set by an agent (recommendation/news), return it
        elif "answer" in state and state["answer"]:
            return state
        
        # Fallback response
        else:
            return {**state, "answer": "TÃ´i khÃ´ng cháº¯c cháº¯n vá» cÃ¢u há»i nÃ y. Báº¡n cÃ³ thá»ƒ há»i láº¡i báº±ng cÃ¡ch khÃ¡c Ä‘Æ°á»£c khÃ´ng? ðŸ¤”"}
    
    def setup_workflow(self):
        """
        Set up the LangGraph workflow for the orchestration agent.
        """
        self.graph = StateGraph(ChatState)
        
        # Add all nodes
        self.graph.add_node("router", self.route_user_input)
        self.graph.add_node("retrieve_docs", self.retrieve_docs)
        self.graph.add_node("recommendation", recommend_car_fast)
        self.graph.add_node("search_news", self.search_news)
        self.graph.add_node("generate_answer", self.generate_answer)
        
        # Set entry point
        self.graph.set_entry_point("router")
        
        # Add conditional routing from router
        self.graph.add_conditional_edges("router", lambda state: state["next_step"], {
            "retrieve_docs": "retrieve_docs",
            "recommendation": "recommendation", 
            "search_news": "search_news",
            "generate_answer": "generate_answer"  # For invalid questions
        })
        
        # Connect all paths to answer generation
        self.graph.add_edge("retrieve_docs", "generate_answer")
        self.graph.add_edge("recommendation", "generate_answer") 
        self.graph.add_edge("search_news", "generate_answer")
        self.graph.add_edge("generate_answer", END)
        
        # Compile the workflow
        self.workflow = self.graph.compile()
        logger.info("Master orchestration workflow compiled successfully")
    
    def process_query(self, question: str, chat_history: List = None) -> Dict[str, Any]:
        """
        Process a user query through the orchestration system.
        """
        if chat_history is None:
            chat_history = []
        
        try:
            result = self.workflow.invoke({
                "question": question,
                "chat_history": chat_history,
                "context_docs": [],
                "answer": "",
                "next_step": ""
            })
            return result
        except Exception as e:
            logger.error(f"Error processing query: {e}")
            return {
                "question": question,
                "answer": "I encountered an error while processing your request. Please try again.",
                "chat_history": chat_history
            }
    
    def add_agent(self, name: str, function, description: str, keywords: List[str]):
        """
        Add a new specialized agent to the orchestration system.
        """
        self.available_agents[name] = {
            "function": function,
            "description": description,
            "keywords": keywords
        }
        
        # Rebuild intent classifier with new agent
        self.setup_intent_classifier()
        logger.info(f"Added new agent: {name}")
    
    def get_available_agents(self) -> Dict[str, Dict[str, Any]]:
        """
        Get information about all available agents.
        """
        return self.available_agents.copy()

    def get_workflow_image(self) -> bytes:
        """
        Returns a PNG image (as bytes) of the LangGraph workflow.
        """
        try:
            return self.workflow.get_graph().draw_mermaid_png()
        except Exception as e:
            logger.error(f"Error generating workflow image: {e}")
            return None
# Create global master orchestration agent instance
master_agent = MasterOrchestrationAgent()
