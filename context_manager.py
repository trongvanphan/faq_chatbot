"""
Context Management and Multi-turn Conversation Implementation
"""

import os
import json
import openai
from datetime import datetime
from typing import List, Dict, Optional
from dotenv import load_dotenv
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from faq_data import FAQ_LIST, FUNCTION_DEFINITIONS, AVAILABLE_FUNCTIONS

# Load environment variables
load_dotenv()

# Configuration
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL", "https://")
MODEL = os.getenv("MODEL_NAME", "GPT-4o-mini")
MAX_TOKENS = int(os.getenv("MAX_TOKENS", "500"))  # Increased for context
TEMPERATURE = float(os.getenv("TEMPERATURE", "0.5"))

# Retry configuration
RETRY_ATTEMPTS = int(os.getenv("RETRY_ATTEMPTS", "3"))
RETRY_WAIT_MIN = int(os.getenv("RETRY_WAIT_MIN", "1"))
RETRY_WAIT_MAX = int(os.getenv("RETRY_WAIT_MAX", "10"))

client = openai.OpenAI(
    base_url=OPENAI_BASE_URL,
    api_key=os.getenv("OPENAI_API_KEY")
)

class ConversationManager:
    """Manages conversation context and history for multi-turn conversations"""
    
    def __init__(self, max_history: int = 10):
        """
        Initialize conversation manager
        
        Args:
            max_history: Maximum number of message pairs to keep in history
        """
        self.conversation_history: List[Dict] = []
        self.max_history = max_history
        self.session_id = self._generate_session_id()
        self.context_summary = ""
        
    def _generate_session_id(self) -> str:
        """Generate a unique session ID"""
        return f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    def add_message(self, role: str, content: str, function_call: Optional[Dict] = None, name: Optional[str] = None):
        """Add a message to conversation history"""
        message = {
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        }
        
        if function_call:
            message["function_call"] = function_call
            
        if name:  # For function messages
            message["name"] = name
            
        self.conversation_history.append(message)
        
        # Keep only recent history to manage token limits
        if len(self.conversation_history) > self.max_history * 2:  # *2 for user+assistant pairs
            # Keep system message and recent exchanges
            self.conversation_history = (
                [msg for msg in self.conversation_history if msg["role"] == "system"] +
                self.conversation_history[-(self.max_history * 2):]
            )
    
    def get_context_messages(self) -> List[Dict]:
        """Get messages formatted for OpenAI API"""
        # Build system prompt with context awareness
        system_prompt = self._build_context_aware_system_prompt()
        
        messages = [{"role": "system", "content": system_prompt}]
        
        # Add conversation history (excluding system messages and timestamps)
        for msg in self.conversation_history:
            if msg["role"] != "system":
                api_msg = {"role": msg["role"], "content": msg["content"]}
                
                if "function_call" in msg:
                    api_msg["function_call"] = msg["function_call"]
                    
                if "name" in msg and msg["role"] == "function":
                    api_msg["name"] = msg["name"]
                    
                messages.append(api_msg)
        
        return messages
    
    def _build_context_aware_system_prompt(self) -> str:
        """Build system prompt that includes conversation context"""
        base_prompt = """B·∫°n l√† m·ªôt tr·ª£ l√Ω AI th√¥ng minh, ƒë√°ng tin c·∫≠y v√† l·ªãch s·ª±, chuy√™n tr·∫£ l·ªùi c√°c c√¢u h·ªèi th∆∞·ªùng g·∫∑p (FAQ) v·ªÅ xe h∆°i v·ªõi kh·∫£ nƒÉng nh·ªõ v√† tham chi·∫øu cu·ªôc tr√≤ chuy·ªán tr∆∞·ªõc ƒë√≥.

Nhi·ªám v·ª• c·ªßa b·∫°n:
1. ƒê·ªçc k·ªπ c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng.
2. Suy lu·∫≠n ƒë·ªÉ x√°c ƒë·ªãnh xem c√¢u h·ªèi c√≥ li√™n quan ƒë·∫øn c√°c m·ª•c trong danh s√°ch FAQ kh√¥ng.
3. N·∫øu c√≥, ƒë∆∞a ra c√¢u tr·∫£ l·ªùi ph√π h·ª£p nh·∫•t d·ª±a tr√™n n·ªôi dung FAQ.
4. N·∫øu kh√¥ng c√≥ c√¢u h·ªèi n√†o ph√π h·ª£p, h√£y l·ªãch s·ª± tr·∫£ l·ªùi r·∫±ng b·∫°n kh√¥ng bi·∫øt.

B·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng c√°c ch·ª©c nƒÉng sau ƒë·ªÉ h·ªó tr·ª£ ng∆∞·ªùi d√πng:
- T√¨m ki·∫øm th√¥ng tin trong c∆° s·ªü d·ªØ li·ªáu FAQ
- ƒê∆∞a ra g·ª£i √Ω xe h∆°i d·ª±a tr√™n lo·∫°i xe
- Cung c·∫•p th√¥ng tin v·ªÅ l·ªãch b·∫£o d∆∞·ª°ng
- ƒê∆∞a ra c√°c m·∫πo ti·∫øt ki·ªám nhi√™n li·ªáu

NGUY√äN T·∫ÆC QUAN TR·ªåNG CHO CU·ªòC TR√í CHUY·ªÜN:
- Nh·ªõ v√† tham chi·∫øu ƒë·∫øn nh·ªØng g√¨ ƒë√£ th·∫£o lu·∫≠n tr∆∞·ªõc ƒë√≥
- Hi·ªÉu c√°c t·ª´ nh∆∞ "n√≥", "xe ƒë√≥", "m·∫´u n√†y" d·ª±a tr√™n ng·ªØ c·∫£nh
- Duy tr√¨ t√≠nh li√™n t·ª•c trong cu·ªôc tr√≤ chuy·ªán
- N·∫øu ng∆∞·ªùi d√πng h·ªèi v·ªÅ th·ª© g√¨ ƒë√≥ ƒë√£ ƒë∆∞·ª£c ƒë·ªÅ c·∫≠p, h√£y tham chi·∫øu l·∫°i

---

V√≠ d·ª• minh h·ªça:

üî∏ V√≠ d·ª• 1:
Ng∆∞·ªùi d√πng: Xe ƒëi·ªán c√≥ ph·∫£i l√† t∆∞∆°ng lai kh√¥ng?
Suy lu·∫≠n:
- C√¢u h·ªèi li√™n quan ƒë·∫øn xu h∆∞·ªõng ph√°t tri·ªÉn ng√†nh √¥ t√¥.
- T√¨m th·∫•y FAQ: "Xe ƒëi·ªán (EV) c√≥ th·ª±c s·ª± l√† t∆∞∆°ng lai c·ªßa ng√†nh √¥ t√¥ kh√¥ng?"
Tr·∫£ l·ªùi: Xe ƒëi·ªán ƒë∆∞·ª£c coi l√† m·ªôt ph·∫ßn quan tr·ªçng c·ªßa t∆∞∆°ng lai ng√†nh √¥ t√¥ do gi·∫£m ph√°t th·∫£i v√† chi ph√≠ v·∫≠n h√†nh th·∫•p h∆°n...

üî∏ V√≠ d·ª• 2:
Ng∆∞·ªùi d√πng: T√¥i n√™n ch·ªçn xe s·ªë s√†n hay xe s·ªë t·ª± ƒë·ªông?
Suy lu·∫≠n:
- C√¢u h·ªèi li√™n quan ƒë·∫øn vi·ªác l·ª±a ch·ªçn gi·ªØa hai lo·∫°i h·ªôp s·ªë.
- T√¨m th·∫•y FAQ: "S·ª± kh√°c bi·ªát gi·ªØa xe s·ªë s√†n v√† xe s·ªë t·ª± ƒë·ªông l√† g√¨?"
Tr·∫£ l·ªùi: Xe s·ªë s√†n y√™u c·∫ßu ng∆∞·ªùi l√°i ph·∫£i t·ª± ƒëi·ªÅu khi·ªÉn c√¥n v√† sang s·ªë... L·ª±a ch·ªçn t√πy thu·ªôc v√†o th√≥i quen l√°i xe v√† m√¥i tr∆∞·ªùng di chuy·ªÉn...

üî∏ V√≠ d·ª• 3:
Ng∆∞·ªùi d√πng: T√¥i n√™n ƒÉn g√¨ ƒë·ªÉ gi·∫£m c√¢n?
Suy lu·∫≠n:
- C√¢u h·ªèi kh√¥ng li√™n quan ƒë·∫øn lƒ©nh v·ª±c √¥ t√¥.
Tr·∫£ l·ªùi: Xin l·ªói, t√¥i kh√¥ng c√≥ th√¥ng tin v·ªÅ c√¢u h·ªèi n√†y v√¨ n√≥ n·∫±m ngo√†i ph·∫°m vi c√°c c√¢u h·ªèi th∆∞·ªùng g·∫∑p v·ªÅ √¥ t√¥.

H√£y s·ª≠ d·ª•ng c√°c ch·ª©c nƒÉng c√≥ s·∫µn v√† duy tr√¨ ng·ªØ c·∫£nh cu·ªôc tr√≤ chuy·ªán ƒë·ªÉ tr·∫£ l·ªùi m·ªôt c√°ch ch√≠nh x√°c v√† t·ª± nhi√™n."""

        # Add context summary if available
        if self.context_summary:
            base_prompt += f"\n\nNG·ªÆ C·∫¢NH CU·ªòC TR√í CHUY·ªÜN:\n{self.context_summary}"
            
        return base_prompt
    
    def update_context_summary(self, new_info: str):
        """Update context summary with new information"""
        if self.context_summary:
            self.context_summary += f" | {new_info}"
        else:
            self.context_summary = new_info
            
        # Keep summary concise
        if len(self.context_summary) > 500:
            # Keep only the most recent context
            parts = self.context_summary.split(" | ")
            self.context_summary = " | ".join(parts[-3:])
    
    def get_conversation_summary(self) -> Dict:
        """Get a summary of the current conversation"""
        return {
            "session_id": self.session_id,
            "message_count": len(self.conversation_history),
            "context_summary": self.context_summary,
            "last_topics": self._extract_recent_topics()
        }
    
    def _extract_recent_topics(self) -> List[str]:
        """Extract recent topics from conversation"""
        topics = []
        for msg in self.conversation_history[-6:]:  # Last 3 exchanges
            if msg["role"] == "user" and msg["content"]:
                # Simple topic extraction
                content = msg["content"].lower()
                if "suv" in content:
                    topics.append("SUV")
                elif "sedan" in content:
                    topics.append("Sedan")
                elif "b·∫£o d∆∞·ª°ng" in content:
                    topics.append("B·∫£o d∆∞·ª°ng")
                elif "ti·∫øt ki·ªám" in content:
                    topics.append("Ti·∫øt ki·ªám nhi√™n li·ªáu")
        return list(set(topics))
    
    def clear_history(self):
        """Clear conversation history"""
        self.conversation_history = []
        self.context_summary = ""

# Global conversation manager
conversation_manager = ConversationManager()

@retry(
    stop=stop_after_attempt(RETRY_ATTEMPTS),
    wait=wait_exponential(multiplier=1, min=RETRY_WAIT_MIN, max=RETRY_WAIT_MAX),
    retry=retry_if_exception_type((openai.APIError, openai.RateLimitError, openai.APITimeoutError, ConnectionError)),
    reraise=True
)
def call_openai_with_retry(messages, functions=None, function_call=None):
    """Call OpenAI API with retry mechanism"""
    try:
        if functions:
            response = client.chat.completions.create(
                model=MODEL,
                messages=messages,
                functions=functions,
                function_call=function_call or "auto",
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE
            )
        else:
            response = client.chat.completions.create(
                model=MODEL,
                messages=messages,
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE
            )
        return response
    except Exception as e:
        print(f"‚ö†Ô∏è API call failed: {str(e)}")
        raise

def execute_function_call(function_name, arguments):
    """Execute the function call and return the result"""
    if function_name in AVAILABLE_FUNCTIONS:
        function = AVAILABLE_FUNCTIONS[function_name]
        try:
            if arguments:
                result = function(**arguments)
            else:
                result = function()
            return json.dumps(result, ensure_ascii=False)
        except Exception as e:
            return json.dumps({"error": f"L·ªói khi th·ª±c thi function: {str(e)}"}, ensure_ascii=False)
    else:
        return json.dumps({"error": "Function kh√¥ng t·ªìn t·∫°i"}, ensure_ascii=False)

def get_contextual_response(user_question: str) -> str:
    """
    Get response with full context management and multi-turn conversation support
    
    Args:
        user_question: The user's current question
        
    Returns:
        Bot's response that considers conversation history
    """
    
    # Add user message to conversation history
    conversation_manager.add_message("user", user_question)
    
    # Get messages with full conversation context
    messages = conversation_manager.get_context_messages()
    
    try:
        print(f"üîÑ Processing question with {len(conversation_manager.conversation_history)} messages of context...")
        
        # First API call with function definitions and conversation history
        response = call_openai_with_retry(
            messages=messages,
            functions=FUNCTION_DEFINITIONS,
            function_call="auto"
        )
        
        message = response.choices[0].message
        
        # Check if the model wants to call a function
        if message.function_call:
            function_name = message.function_call.name
            function_args = json.loads(message.function_call.arguments)
            
            print(f"üîß Executing function: {function_name} with args: {function_args}")
            
            # Execute the function
            function_result = execute_function_call(function_name, function_args)
            
            # Add function call to conversation history
            conversation_manager.add_message(
                "assistant", 
                None, 
                function_call={"name": function_name, "arguments": message.function_call.arguments}
            )
            conversation_manager.add_message("function", function_result, name=function_name)
            
            # Update context summary
            if function_name == "get_car_recommendations":
                car_type = function_args.get("car_type", "xe")
                conversation_manager.update_context_summary(f"ƒê√£ t∆∞ v·∫•n xe {car_type}")
            elif function_name == "get_maintenance_info":
                service = function_args.get("service_type", "b·∫£o d∆∞·ª°ng")
                conversation_manager.update_context_summary(f"ƒê√£ t∆∞ v·∫•n {service}")
            
            # Get updated messages with function result
            messages = conversation_manager.get_context_messages()
            
            # Second API call to get the final response
            print("üîÑ Getting contextualized final response...")
            final_response = call_openai_with_retry(messages=messages)
            
            final_answer = final_response.choices[0].message.content.strip()
        else:
            # No function call needed, return the direct response
            final_answer = message.content.strip()
        
        # Add assistant response to conversation history
        conversation_manager.add_message("assistant", final_answer)
        
        print(f"üí≠ Conversation context: {conversation_manager.get_conversation_summary()}")
        
        return final_answer
            
    except Exception as e:
        error_msg = f"‚ùå ƒê√£ x·∫£y ra l·ªói sau {RETRY_ATTEMPTS} l·∫ßn th·ª≠: {str(e)}"
        print(error_msg)
        return f"Xin l·ªói, t√¥i ƒëang g·∫∑p s·ª± c·ªë k·ªπ thu·∫≠t. Vui l√≤ng th·ª≠ l·∫°i sau. ({str(e)})"

def get_conversation_info() -> Dict:
    """Get current conversation information"""
    return conversation_manager.get_conversation_summary()

def reset_conversation():
    """Reset the conversation context"""
    conversation_manager.clear_history()
    print("üîÑ Conversation context has been reset.")

# Compatibility functions
def get_faq_answer_with_functions(user_question: str) -> str:
    """Wrapper for backward compatibility"""
    return get_contextual_response(user_question)
