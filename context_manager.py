"""
Context Management and Multi-turn Conversation Implementation
"""

import os
import json
import openai
from datetime import datetime
from typing import List, Dict, Optional
from dotenv import load_dotenv
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from faq_data import FAQ_LIST, FUNCTION_DEFINITIONS, AVAILABLE_FUNCTIONS

# Load environment variables
load_dotenv()

# Configuration
OPENAI_BASE_URL = os.getenv("OPENAI_BASE_URL", "https://")
MODEL = os.getenv("MODEL_NAME", "GPT-4o-mini")
MAX_TOKENS = int(os.getenv("MAX_TOKENS", "500"))  # Increased for context
TEMPERATURE = float(os.getenv("TEMPERATURE", "0.5"))

# Retry configuration
RETRY_ATTEMPTS = int(os.getenv("RETRY_ATTEMPTS", "3"))
RETRY_WAIT_MIN = int(os.getenv("RETRY_WAIT_MIN", "1"))
RETRY_WAIT_MAX = int(os.getenv("RETRY_WAIT_MAX", "10"))

client = openai.OpenAI(
    base_url=OPENAI_BASE_URL,
    api_key=os.getenv("OPENAI_API_KEY")
)

class ConversationManager:
    """Manages conversation context and history for multi-turn conversations"""
    
    def __init__(self, max_history: int = 10):
        """
        Initialize conversation manager
        
        Args:
            max_history: Maximum number of message pairs to keep in history
        """
        self.conversation_history: List[Dict] = []
        self.max_history = max_history
        self.session_id = self._generate_session_id()
        self.context_summary = ""
        
    def _generate_session_id(self) -> str:
        """Generate a unique session ID"""
        return f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    def add_message(self, role: str, content: str, function_call: Optional[Dict] = None, name: Optional[str] = None):
        """Add a message to conversation history"""
        message = {
            "role": role,
            "content": content,
            "timestamp": datetime.now().isoformat()
        }
        
        if function_call:
            message["function_call"] = function_call
            
        if name:  # For function messages
            message["name"] = name
            
        self.conversation_history.append(message)
        
        # Keep only recent history to manage token limits
        if len(self.conversation_history) > self.max_history * 2:  # *2 for user+assistant pairs
            # Keep system message and recent exchanges
            self.conversation_history = (
                [msg for msg in self.conversation_history if msg["role"] == "system"] +
                self.conversation_history[-(self.max_history * 2):]
            )
    
    def get_context_messages(self) -> List[Dict]:
        """Get messages formatted for OpenAI API"""
        # Build system prompt with context awareness
        system_prompt = self._build_context_aware_system_prompt()
        
        messages = [{"role": "system", "content": system_prompt}]
        
        # Add conversation history (excluding system messages and timestamps)
        for msg in self.conversation_history:
            if msg["role"] != "system":
                api_msg = {"role": msg["role"], "content": msg["content"]}
                
                if "function_call" in msg:
                    api_msg["function_call"] = msg["function_call"]
                    
                if "name" in msg and msg["role"] == "function":
                    api_msg["name"] = msg["name"]
                    
                messages.append(api_msg)
        
        return messages
    
    def _build_context_aware_system_prompt(self) -> str:
        """Build system prompt that includes conversation context"""
        base_prompt = """Báº¡n lÃ  má»™t trá»£ lÃ½ AI thÃ´ng minh, Ä‘Ã¡ng tin cáº­y vÃ  lá»‹ch sá»±, chuyÃªn tráº£ lá»i cÃ¡c cÃ¢u há»i thÆ°á»ng gáº·p (FAQ) vá» xe hÆ¡i vá»›i kháº£ nÄƒng nhá»› vÃ  tham chiáº¿u cuá»™c trÃ² chuyá»‡n trÆ°á»›c Ä‘Ã³.

Nhiá»‡m vá»¥ cá»§a báº¡n:
1. Äá»c ká»¹ cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng.
2. Suy luáº­n Ä‘á»ƒ xÃ¡c Ä‘á»‹nh xem cÃ¢u há»i cÃ³ liÃªn quan Ä‘áº¿n cÃ¡c má»¥c trong danh sÃ¡ch FAQ khÃ´ng.
3. Náº¿u cÃ³, Ä‘Æ°a ra cÃ¢u tráº£ lá»i phÃ¹ há»£p nháº¥t dá»±a trÃªn ná»™i dung FAQ.
4. Náº¿u khÃ´ng cÃ³ cÃ¢u há»i nÃ o phÃ¹ há»£p, hÃ£y lá»‹ch sá»± tráº£ lá»i ráº±ng báº¡n khÃ´ng biáº¿t.

Báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c chá»©c nÄƒng sau Ä‘á»ƒ há»— trá»£ ngÆ°á»i dÃ¹ng:
- TÃ¬m kiáº¿m thÃ´ng tin trong cÆ¡ sá»Ÿ dá»¯ liá»‡u FAQ
- ÄÆ°a ra gá»£i Ã½ xe hÆ¡i dá»±a trÃªn loáº¡i xe
- Cung cáº¥p thÃ´ng tin vá» lá»‹ch báº£o dÆ°á»¡ng
- ÄÆ°a ra cÃ¡c máº¹o tiáº¿t kiá»‡m nhiÃªn liá»‡u

NGUYÃŠN Táº®C QUAN TRá»ŒNG CHO CUá»˜C TRÃ’ CHUYá»†N:
- Nhá»› vÃ  tham chiáº¿u Ä‘áº¿n nhá»¯ng gÃ¬ Ä‘Ã£ tháº£o luáº­n trÆ°á»›c Ä‘Ã³
- Hiá»ƒu cÃ¡c tá»« nhÆ° "nÃ³", "xe Ä‘Ã³", "máº«u nÃ y" dá»±a trÃªn ngá»¯ cáº£nh
- Duy trÃ¬ tÃ­nh liÃªn tá»¥c trong cuá»™c trÃ² chuyá»‡n
- Náº¿u ngÆ°á»i dÃ¹ng há»i vá» thá»© gÃ¬ Ä‘Ã³ Ä‘Ã£ Ä‘Æ°á»£c Ä‘á» cáº­p, hÃ£y tham chiáº¿u láº¡i

---

VÃ­ dá»¥ minh há»a:

ðŸ”¸ VÃ­ dá»¥ 1:
NgÆ°á»i dÃ¹ng: Xe Ä‘iá»‡n cÃ³ pháº£i lÃ  tÆ°Æ¡ng lai khÃ´ng?
Suy luáº­n:
- CÃ¢u há»i liÃªn quan Ä‘áº¿n xu hÆ°á»›ng phÃ¡t triá»ƒn ngÃ nh Ã´ tÃ´.
- TÃ¬m tháº¥y FAQ: "Xe Ä‘iá»‡n (EV) cÃ³ thá»±c sá»± lÃ  tÆ°Æ¡ng lai cá»§a ngÃ nh Ã´ tÃ´ khÃ´ng?"
Tráº£ lá»i: Xe Ä‘iá»‡n Ä‘Æ°á»£c coi lÃ  má»™t pháº§n quan trá»ng cá»§a tÆ°Æ¡ng lai ngÃ nh Ã´ tÃ´ do giáº£m phÃ¡t tháº£i vÃ  chi phÃ­ váº­n hÃ nh tháº¥p hÆ¡n...

ðŸ”¸ VÃ­ dá»¥ 2:
NgÆ°á»i dÃ¹ng: TÃ´i nÃªn chá»n xe sá»‘ sÃ n hay xe sá»‘ tá»± Ä‘á»™ng?
Suy luáº­n:
- CÃ¢u há»i liÃªn quan Ä‘áº¿n viá»‡c lá»±a chá»n giá»¯a hai loáº¡i há»™p sá»‘.
- TÃ¬m tháº¥y FAQ: "Sá»± khÃ¡c biá»‡t giá»¯a xe sá»‘ sÃ n vÃ  xe sá»‘ tá»± Ä‘á»™ng lÃ  gÃ¬?"
Tráº£ lá»i: Xe sá»‘ sÃ n yÃªu cáº§u ngÆ°á»i lÃ¡i pháº£i tá»± Ä‘iá»u khiá»ƒn cÃ´n vÃ  sang sá»‘... Lá»±a chá»n tÃ¹y thuá»™c vÃ o thÃ³i quen lÃ¡i xe vÃ  mÃ´i trÆ°á»ng di chuyá»ƒn...

ðŸ”¸ VÃ­ dá»¥ 3:
NgÆ°á»i dÃ¹ng: TÃ´i nÃªn Äƒn gÃ¬ Ä‘á»ƒ giáº£m cÃ¢n?
Suy luáº­n:
- CÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n lÄ©nh vá»±c Ã´ tÃ´.
Tráº£ lá»i: Xin lá»—i, tÃ´i khÃ´ng cÃ³ thÃ´ng tin vá» cÃ¢u há»i nÃ y vÃ¬ nÃ³ náº±m ngoÃ i pháº¡m vi cÃ¡c cÃ¢u há»i thÆ°á»ng gáº·p vá» Ã´ tÃ´.

HÃ£y sá»­ dá»¥ng cÃ¡c chá»©c nÄƒng cÃ³ sáºµn vÃ  duy trÃ¬ ngá»¯ cáº£nh cuá»™c trÃ² chuyá»‡n Ä‘á»ƒ tráº£ lá»i má»™t cÃ¡ch chÃ­nh xÃ¡c vÃ  tá»± nhiÃªn."""

        # Add context summary if available
        if self.context_summary:
            base_prompt += f"\n\nNGá»® Cáº¢NH CUá»˜C TRÃ’ CHUYá»†N:\n{self.context_summary}"
            
        return base_prompt
    
    def update_context_summary(self, new_info: str):
        """Update context summary with new information"""
        if self.context_summary:
            self.context_summary += f" | {new_info}"
        else:
            self.context_summary = new_info
            
        # Keep summary concise
        if len(self.context_summary) > 500:
            # Keep only the most recent context
            parts = self.context_summary.split(" | ")
            self.context_summary = " | ".join(parts[-3:])
    
    def get_conversation_summary(self) -> Dict:
        """Get a summary of the current conversation"""
        return {
            "session_id": self.session_id,
            "message_count": len(self.conversation_history),
            "context_summary": self.context_summary,
            "last_topics": self._extract_recent_topics()
        }
    
    def _extract_recent_topics(self) -> List[str]:
        """Extract recent topics from conversation"""
        topics = []
        for msg in self.conversation_history[-6:]:  # Last 3 exchanges
            if msg["role"] == "user" and msg["content"]:
                # Simple topic extraction
                content = msg["content"].lower()
                if "suv" in content:
                    topics.append("SUV")
                elif "sedan" in content:
                    topics.append("Sedan")
                elif "báº£o dÆ°á»¡ng" in content:
                    topics.append("Báº£o dÆ°á»¡ng")
                elif "tiáº¿t kiá»‡m" in content:
                    topics.append("Tiáº¿t kiá»‡m nhiÃªn liá»‡u")
        return list(set(topics))
    
    def clear_history(self):
        """Clear conversation history"""
        self.conversation_history = []
        self.context_summary = ""

# Global conversation manager
conversation_manager = ConversationManager()

@retry(
    stop=stop_after_attempt(RETRY_ATTEMPTS),
    wait=wait_exponential(multiplier=1, min=RETRY_WAIT_MIN, max=RETRY_WAIT_MAX),
    retry=retry_if_exception_type((openai.APIError, openai.RateLimitError, openai.APITimeoutError, ConnectionError)),
    reraise=True
)
def call_openai_with_retry(messages, functions=None, function_call=None):
    """Call OpenAI API with retry mechanism"""
    try:
        if functions:
            response = client.chat.completions.create(
                model=MODEL,
                messages=messages,
                functions=functions,
                function_call=function_call or "auto",
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE
            )
        else:
            response = client.chat.completions.create(
                model=MODEL,
                messages=messages,
                max_tokens=MAX_TOKENS,
                temperature=TEMPERATURE
            )
        return response
    except Exception as e:
        print(f"âš ï¸ API call failed: {str(e)}")
        raise

def execute_function_call(function_name, arguments):
    """Execute the function call and return the result"""
    if function_name in AVAILABLE_FUNCTIONS:
        function = AVAILABLE_FUNCTIONS[function_name]
        try:
            if arguments:
                result = function(**arguments)
            else:
                result = function()
            return json.dumps(result, ensure_ascii=False)
        except Exception as e:
            return json.dumps({"error": f"Lá»—i khi thá»±c thi function: {str(e)}"}, ensure_ascii=False)
    else:
        return json.dumps({"error": "Function khÃ´ng tá»“n táº¡i"}, ensure_ascii=False)

def get_contextual_response(user_question: str) -> str:
    """
    Get response with full context management and multi-turn conversation support
    
    Args:
        user_question: The user's current question
        
    Returns:
        Bot's response that considers conversation history
    """
    
    # Add user message to conversation history
    conversation_manager.add_message("user", user_question)
    
    # Get messages with full conversation context
    messages = conversation_manager.get_context_messages()
    
    try:
        print(f"ðŸ”„ Processing question with {len(conversation_manager.conversation_history)} messages of context...")
        
        # First API call with function definitions and conversation history
        response = call_openai_with_retry(
            messages=messages,
            functions=FUNCTION_DEFINITIONS,
            function_call="auto"
        )
        
        message = response.choices[0].message
        
        # Check if the model wants to call a function
        if message.function_call:
            function_name = message.function_call.name
            function_args = json.loads(message.function_call.arguments)
            
            print(f"ðŸ”§ Executing function: {function_name} with args: {function_args}")
            
            # Execute the function
            function_result = execute_function_call(function_name, function_args)
            
            # Add function call to conversation history
            conversation_manager.add_message(
                "assistant", 
                None, 
                function_call={"name": function_name, "arguments": message.function_call.arguments}
            )
            conversation_manager.add_message("function", function_result, name=function_name)
            
            # Update context summary
            if function_name == "get_car_recommendations":
                car_type = function_args.get("car_type", "xe")
                conversation_manager.update_context_summary(f"ÄÃ£ tÆ° váº¥n xe {car_type}")
            elif function_name == "get_maintenance_info":
                service = function_args.get("service_type", "báº£o dÆ°á»¡ng")
                conversation_manager.update_context_summary(f"ÄÃ£ tÆ° váº¥n {service}")
            
            # Get updated messages with function result
            messages = conversation_manager.get_context_messages()
            
            # Second API call to get the final response
            print("ðŸ”„ Getting contextualized final response...")
            final_response = call_openai_with_retry(messages=messages)
            
            final_answer = final_response.choices[0].message.content.strip()
        else:
            # No function call needed, return the direct response
            final_answer = message.content.strip()
        
        # Add assistant response to conversation history
        conversation_manager.add_message("assistant", final_answer)
        
        print(f"ðŸ’­ Conversation context: {conversation_manager.get_conversation_summary()}")
        
        return final_answer
            
    except Exception as e:
        error_msg = f"âŒ ÄÃ£ xáº£y ra lá»—i sau {RETRY_ATTEMPTS} láº§n thá»­: {str(e)}"
        print(error_msg)
        return f"Xin lá»—i, tÃ´i Ä‘ang gáº·p sá»± cá»‘ ká»¹ thuáº­t. Vui lÃ²ng thá»­ láº¡i sau. ({str(e)})"

def get_conversation_info() -> Dict:
    """Get current conversation information"""
    return conversation_manager.get_conversation_summary()

def reset_conversation():
    """Reset the conversation context"""
    conversation_manager.clear_history()
    print("ðŸ”„ Conversation context has been reset.")

# Compatibility functions
def get_faq_answer_with_functions(user_question: str) -> str:
    """Wrapper for backward compatibility"""
    return get_contextual_response(user_question)
